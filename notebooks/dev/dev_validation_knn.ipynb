{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e14313eb-b15a-4f8d-a637-09e74a8d6b73",
   "metadata": {},
   "source": [
    "# validate knn\n",
    "\n",
    "Sometimes we want to run validation on a self-supervised model without training a linear probe.\n",
    "\n",
    "To do so, we can do one of two nearest-neighbot classifiers:\n",
    "1) get the embeddings for all training images, compare each val image to each training image, choose the K nearest neighbors (default = 200) and perform a similarity-weighted voting for the target class,\n",
    "2) use training images to compute the prototype for each class, the simply assign each val image the class of the nearest-neighbor prototype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbce2955-93eb-43e0-b04a-1ad1df1e9644",
   "metadata": {},
   "source": [
    "# ipcl code vs. deep_analytics\n",
    "\n",
    "To make sure we port the code correctly, let's get scores with original IPCL code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce96052-8dff-4af8-894d-5417648e6df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from deep_analytics.datasets.folder import ImageNetIndex\n",
    "from lib.knn import run_kNN_chunky\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "run_kNN_chunky?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6091935e-276a-42e4-b175-df2547bae8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, transform = torch.hub.load(\"harvard-visionlab/open_ipcl\", \"alexnetgn_ipcl_ref01\",\n",
    "                                  trust_repo=True, force_reload=True)\n",
    "model.to(device)\n",
    "transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89058626-334a-4870-b241-2551f1cca926",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/n/alvarez_lab_tier1/Users/alvarez/datasets/imagenet1k-256'\n",
    "train_dataset = ImageNetIndex(root, split='train', transform=transform)\n",
    "print(train_dataset)\n",
    "test_dataset = ImageNetIndex(root, split='val', transform=transform)\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985e4394-1560-4a73-b0e7-4d5f8c87fd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "num_workers=len(os.sched_getaffinity(0))\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers, \n",
    "                          shuffle=False, pin_memory=True, drop_last=False)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=num_workers, \n",
    "                         shuffle=False, pin_memory=True, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b571001c-05d0-4647-b435-e0aa3c9bb640",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_name = 'fc8'\n",
    "top1, top5 = run_kNN_chunky(model,\n",
    "                            train_loader,\n",
    "                            test_loader,\n",
    "                            layer_name,\n",
    "                            K=200,\n",
    "                            sigma=0.07,\n",
    "                            num_chunks=10,\n",
    "                            out_device=None)\n",
    "top1, top5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dae5259-927c-480f-9eef-435e5709f537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ({'fc8': 39.173999428749084}, {'fc8': 61.40999794006348})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81facc2-e28e-44ff-b8bf-69b8e1454a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_analytics.assays.cls_accuracy.knn import run_kNN\n",
    "\n",
    "layer_names = ['ave_pool', 'fc6', 'fc7', 'fc8']\n",
    "results = run_kNN(model, train_loader, test_loader, layer_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504aa1f3-a873-42ec-a20c-24f51ff4cfbe",
   "metadata": {},
   "source": [
    "# prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a220cb5e-4c4c-48b0-91c9-e91e239329f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_analytics.assays.cls_accuracy.knn import run_kNN\n",
    "\n",
    "layer_names = ['fc7', 'fc8']\n",
    "top1, top5, prototypes, features, labels = run_kNN(model, train_loader, test_loader, \n",
    "                                                   layer_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7020d772-9fa4-4159-a5f5-0f0caa6a5dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(dict(\n",
    "    top1=top1,\n",
    "    top5=top5,\n",
    "    prototypes=prototypes,\n",
    "    features=features,\n",
    "    labels=labels\n",
    "), './results/prototypes.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1cfd48-d212-47cf-8634-3c16d9f19b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mahalanobis_distance(x, y, covariance):\n",
    "    \"\"\"\n",
    "    Compute the Mahalanobis distance between a test item and a prototype.\n",
    "\n",
    "    Parameters:\n",
    "    x: Tensor of shape (num_features,) representing the test item.\n",
    "    y: Tensor of shape (num_features,) representing the prototype mean.\n",
    "    covariance: Tensor of shape (num_features, num_features) representing the covariance matrix of the prototype.\n",
    "\n",
    "    Returns:\n",
    "    The Mahalanobis distance as a scalar.\n",
    "    \"\"\"\n",
    "    diff = x - y\n",
    "    # Ensure the covariance matrix is invertible\n",
    "    if torch.det(covariance) == 0:\n",
    "        raise ValueError(\"Covariance matrix is not invertible.\")\n",
    "    inv_covariance = torch.inverse(covariance)\n",
    "    distance_squared = torch.matmul(torch.matmul(diff.view(1, -1), inv_covariance), diff.view(-1, 1))\n",
    "    return torch.sqrt(distance_squared).item()\n",
    "\n",
    "def compute_mahalanobis(test_means, proto_means, proto_vars):\n",
    "    \"\"\"\n",
    "    Compute the Mahalanobis distance between test items and prototypes.\n",
    "\n",
    "    Parameters:\n",
    "    test_means: Tensor of shape (num_tests, num_features)\n",
    "    proto_means: Tensor of shape (num_protos, num_features)\n",
    "    proto_vars: Tensor of shape (num_protos, num_features)\n",
    "\n",
    "    Returns:\n",
    "    distances: Tensor of shape (num_tests, num_protos)\n",
    "    \"\"\"\n",
    "    num_tests, num_features = test_means.shape\n",
    "    num_protos, _ = proto_means.shape\n",
    "\n",
    "    # Invert the variance to get the diagonal elements of the precision matrix\n",
    "    precision_diag = 1.0 / proto_vars  # shape: (num_protos, num_features)\n",
    "\n",
    "    # Expand dimensions for broadcasting\n",
    "    test_means_exp = test_means.unsqueeze(1).expand(num_tests, num_protos, num_features)\n",
    "    proto_means_exp = proto_means.unsqueeze(0).expand(num_tests, num_protos, num_features)\n",
    "    precision_diag_exp = precision_diag.unsqueeze(0).expand(num_tests, num_protos, num_features)\n",
    "\n",
    "    # Compute the Mahalanobis distance\n",
    "    diff = test_means_exp - proto_means_exp\n",
    "    distances = (diff ** 2 * precision_diag_exp).sum(dim=2).sqrt()\n",
    "\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c315e65c-2f6e-4243-9aa2-8d0429fbde02",
   "metadata": {},
   "source": [
    "# ClassificationKNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661513f3-cb4b-400d-be14-f3a86bdda3a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4341f11-4cb9-4554-96bd-75ec946d4701",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5bb9af-d53c-4cb5-8788-540743c69cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import gc\n",
    "from collections import defaultdict\n",
    "from contextlib import redirect_stdout\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchattacks\n",
    "import matplotlib.pyplot as plt\n",
    "from fastprogress import master_bar, progress_bar\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "from deep_analytics.assays.model_assay import ModelAssay\n",
    "from deep_analytics.utils.bootstrap import bootstrap_multi_dim\n",
    "from deep_analytics.utils.stats import AccumMetric\n",
    "# from deep_analytics.assays.metrics import *\n",
    "from deep_analytics.utils.feature_extractor import FeatureExtractor\n",
    "\n",
    "from pdb import set_trace\n",
    "\n",
    "from types import SimpleNamespace\n",
    "\n",
    "__all__ = ['ClassificationNearestNeighbors', 'ClassificationNearestPrototype']\n",
    "\n",
    "class ClassificationNearestNeighbors(ModelAssay):\n",
    "    \n",
    "    datasets = dict(\n",
    "        imagenette2=('imagenette2_s320_remap1k', 'val'),\n",
    "        imagenet1k=('imagenet1k_s256', 'val'),\n",
    "        imagenetV2_top_images=('imagenetV2', 'top-images'),\n",
    "        imagenetV2_threshold07=('imagenetV2', 'threshold0.7'),\n",
    "        imagenetV2_matched_frequency=('imagenetV2', 'matched-frequency')\n",
    "    )\n",
    "\n",
    "    def compute_metrics(self, df):\n",
    "        raise NotImplementedError(\"Subclasses of ModelAssay should implement `compute_metrics`.\")\n",
    "        \n",
    "    def plot_results(self, df):\n",
    "        raise NotImplementedError(\"Subclasses of ModelAssay should implement `plot_results`.\")\n",
    "    \n",
    "    def __call__(self, model_or_model_loader, transform):\n",
    "        self.dataloader = self.get_dataloader(transform)        \n",
    "        \n",
    "        if isinstance(model_or_model_loader, nn.Module):\n",
    "            model = model_or_model_loader\n",
    "        else:\n",
    "            model = model_or_model_loader()\n",
    "\n",
    "        df = validate(model, self.dataloader)\n",
    "        df['model_name'] = model.__dict__.get(\"model_name\", model.__class__.__name__)\n",
    "        df['dataset'] = self.dataset_name\n",
    "\n",
    "        # Clear the cache\n",
    "        del model\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "            \n",
    "        return df\n",
    "     \n",
    "@torch.no_grad()        \n",
    "def run_kNN(model, train_loader, test_loader, layer_names, num_classes=1000, \n",
    "            K=200, sigma=.07, num_chunks=10, out_device=None):\n",
    "    '''\n",
    "        we compute the full testFeatures, testLabels,\n",
    "        \n",
    "        then we iterate over the training set in batches, accumulating `num_chunks` (should\n",
    "        be `num_batches`, but keeping the naming the same as run_kNN for api consistency).\n",
    "        \n",
    "        Finally we have the paiwise similarity between each val and each train image.\n",
    "    '''\n",
    "    \n",
    "    if isinstance(layer_names, str):\n",
    "        layer_names = [layer_names]\n",
    "        \n",
    "    if out_device is None:\n",
    "        out_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        \n",
    "    print(\"==> extracting test features...\")\n",
    "    testFeatures, testLabels, indexes = get_features(model, test_loader, layer_names,\n",
    "                                                     out_device=out_device)    \n",
    "    \n",
    "    print(\"==> extracting/comparing to train features...\")\n",
    "    topk_distances = defaultdict(lambda: torch.tensor([], device=out_device))\n",
    "    trainLabels = defaultdict(lambda: torch.tensor([], device=out_device, dtype=torch.int64))\n",
    "    trainIndexes = defaultdict(lambda: torch.tensor([], device=out_device, dtype=torch.int64))\n",
    "    \n",
    "    generator = gen_features(model, train_loader, layer_names, num_batches=num_chunks,\n",
    "                             out_device=out_device)\n",
    "    for batch_num, (trn_feat, trn_labels, trn_indexes) in enumerate(generator):                 \n",
    "        for layer_name in layer_names:\n",
    "            \n",
    "            # compute distances between testFeatures and current train features\n",
    "            d = torch.mm(testFeatures[layer_name], \n",
    "                         trn_feat[layer_name].T).to(out_device)\n",
    "            \n",
    "            # append these distances to running topk_distances\n",
    "            topk_distances[layer_name] = torch.cat([topk_distances[layer_name], d], dim=1)\n",
    "            \n",
    "            # reshape train_labels (numTestImgs x numTrainImagesThisBatch)\n",
    "            candidate_labels = trn_labels.view(1,-1).expand(len(testLabels), -1)\n",
    "            # concat with retained trainLabels\n",
    "            trainLabels[layer_name] = torch.cat([trainLabels[layer_name], \n",
    "                                                 candidate_labels], dim=1)\n",
    "        \n",
    "            # reshape train_indexes (numTestImgs x numTrainImagesThisBatch)\n",
    "            candidate_indexes = trn_indexes.view(1,-1).expand(len(testLabels), -1)\n",
    "            # concat with retained trainIndexes\n",
    "            trainIndexes[layer_name] = torch.cat([trainIndexes[layer_name], \n",
    "                                                  candidate_indexes], dim=1)\n",
    "        \n",
    "            # keep the top K distances and labels  \n",
    "            yd, yi = topk_distances[layer_name].topk(K, dim=1, largest=True, sorted=True)\n",
    "            topk_distances[layer_name] = torch.gather(topk_distances[layer_name], 1, yi)\n",
    "            trainLabels[layer_name] = torch.gather(trainLabels[layer_name], 1, yi)\n",
    "            trainIndexes[layer_name] = torch.gather(trainIndexes[layer_name], 1, yi)\n",
    "    \n",
    "    # After iterating through the full training set, we have retained\n",
    "    # the topk_distances, topk_labels, topk_indexes for the topk most\n",
    "    # similar training items for each individual test item\n",
    "    # generate weighted predictions.\n",
    "    \n",
    "    # Finally, we compute the predicted class through a similarity-weighted\n",
    "    # voting amongst the topK separately for each layer\n",
    "    print(\"==> computing top1,top5 accurcy: ...\")\n",
    "    top1_acc = dict()\n",
    "    top5_acc = dict()\n",
    "    \n",
    "    for layer_name in progress_bar(layer_names):\n",
    "        distances = topk_distances[layer_name]\n",
    "        train_labels = trainLabels[layer_name]\n",
    "        \n",
    "        pred, top1, top5 = compute_knn_accuracy(distances, \n",
    "                                                train_labels, \n",
    "                                                testLabels, \n",
    "                                                num_classes=num_classes, \n",
    "                                                sigma=sigma)\n",
    "        \n",
    "        top1 = top1.float().sum(dim=1).mean().item() * 100\n",
    "        top5 = top5.float().sum(dim=1).mean().item() * 100\n",
    "        \n",
    "        print(f\"kNN accuracy {layer_name}: top1={top1}, top5={top5}\")\n",
    "        top1_acc[layer_name] = top1\n",
    "        top5_acc[layer_name] = top5\n",
    "        \n",
    "    return top1_acc, top5_acc\n",
    "\n",
    "def compute_knn_accuracy(distances, train_labels, test_labels, num_classes, sigma):\n",
    "    \"\"\"\n",
    "    Computes the k-NN classification accuracy.\n",
    "\n",
    "    :param distances: Tensor of distances between test and training features (num_Test x topK_Train)\n",
    "    :param train_labels: Labels corresponding to the training data (num_Test x topK_Train)\n",
    "    :param test_labels: Labels corresponding to the test data.\n",
    "    :param num_classes: Total number of classes.\n",
    "    :param sigma: Scaling parameter for distance transformation.\n",
    "    :return: Tuple of (predictions, top1 accuracy, top5 accuracy)\n",
    "    \"\"\"\n",
    "    num_test_images, K = train_labels.shape\n",
    "    retrieval_one_hot = torch.zeros(K, num_classes).to('cpu')\n",
    "    retrieval_one_hot.resize_(num_test_images * K, num_classes).zero_()\n",
    "    retrieval_one_hot.scatter_(1, train_labels.view(-1, 1).cpu(), 1)\n",
    "    yd_transform = distances.clone().div_(sigma).exp_().cpu()\n",
    "    probs = torch.sum(torch.mul(retrieval_one_hot.view(num_test_images, -1 , num_classes), \n",
    "                                yd_transform.view(num_test_images, -1, 1)), 1)\n",
    "    _, predictions = probs.sort(1, True)\n",
    "\n",
    "    # Find which predictions match the target\n",
    "    correct = predictions.eq(test_labels.view(-1,1).cpu())\n",
    "\n",
    "    total = correct.size(0)\n",
    "    top1 = correct.narrow(1,0,1)\n",
    "    \n",
    "    # Handle the case where the number of predictions is less than 5\n",
    "    top_k = min(5, predictions.size(1))\n",
    "    top5 = correct.narrow(1,0,top_k)\n",
    "    \n",
    "    return predictions, top1, top5\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_features(model, dataloader, layer_names, device=None, out_device=None):    \n",
    "    \n",
    "    if isinstance(layer_names, str):\n",
    "        layer_names = [layer_names]\n",
    "        \n",
    "    if device is None:\n",
    "        device = next(model.parameters()).device\n",
    "        \n",
    "    if out_device is None:\n",
    "        out_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    features,labels,indexes = defaultdict(list),[],[]\n",
    "    \n",
    "    with FeatureExtractor(model, layer_names, device=out_device) as extractor:\n",
    "        for imgs,targs,idxs in progress_bar(dataloader):\n",
    "            feat = extractor(imgs.to(device, non_blocking=True))\n",
    "            \n",
    "            for layer_name,X in feat.items():\n",
    "                X = X.flatten(start_dim=1)\n",
    "                X = F.normalize(X, dim=1)\n",
    "                features[layer_name].append(X.to(out_device))\n",
    "            labels.append(targs.to(out_device))\n",
    "            indexes.append(idxs.to(out_device))\n",
    "    \n",
    "    for layer_name in layer_names:\n",
    "        features[layer_name] = torch.cat(features[layer_name])\n",
    "    labels = torch.cat(labels)\n",
    "    indexes = torch.cat(indexes)\n",
    "    \n",
    "    return features, labels, indexes\n",
    "\n",
    "@torch.no_grad()\n",
    "def gen_features(model, dataloader, layer_names, num_batches=10, device=None, out_device=None):    \n",
    "    \n",
    "    if isinstance(layer_names, str):\n",
    "        layer_names = [layer_names]\n",
    "        \n",
    "    if device is None:\n",
    "        device = next(model.parameters()).device\n",
    "        \n",
    "    if out_device is None:\n",
    "        out_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "                \n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    features,targets,indexes = defaultdict(list), [], []\n",
    "    batch_count=0\n",
    "    for batch_num,(imgs,targs,idxs) in enumerate(progress_bar(dataloader)):\n",
    "        batch_count+=1\n",
    "        imgs = imgs.to(device, non_blocking=True)      \n",
    "        with FeatureExtractor(model, layer_names, device=out_device) as extractor:\n",
    "            feat = extractor(imgs)\n",
    "        \n",
    "        # normalize and aggregate features\n",
    "        for layer_name,X in feat.items():\n",
    "            X = X.flatten(start_dim=1) # flatten from dim1 onward\n",
    "            X = F.normalize(X, dim=1)  # normalize across features\n",
    "            features[layer_name].append(X.to(out_device))\n",
    "            targets.append(targs.to(out_device))\n",
    "            indexes.append(idxs.to(out_device))\n",
    "        \n",
    "        if batch_count==num_batches:\n",
    "            #print(f\"==> batch_num={batch_num}, batch_count={batch_count}\")\n",
    "            for layer_name in layer_names:\n",
    "                features[layer_name] = torch.cat(features[layer_name])\n",
    "            targets = torch.cat(targets)\n",
    "            indexes = torch.cat(indexes)   \n",
    "            yield features, targets, indexes\n",
    "            features,targets,indexes = defaultdict(list), [], []\n",
    "            batch_count=0\n",
    "    \n",
    "    # yield any remaining features\n",
    "    if len(features[layer_name]) > 0:\n",
    "        #print(\"==> wait, there's more!\")\n",
    "        for layer_name in layer_names:\n",
    "            features[layer_name] = torch.cat(features[layer_name])\n",
    "        targets = torch.cat(targets)\n",
    "        indexes = torch.cat(indexes)\n",
    "\n",
    "        yield features, targets, indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df14c91f-4632-482c-9bfa-3d83125fa867",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_names = ['fc8']\n",
    "results = run_kNN(model, train_loader, test_loader, layer_names=layer_names)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebf97f4-2fa2-4b21-a3ad-c7a64c6c72c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_names = ['classifier.6']\n",
    "results = run_kNN(model, train_loader, test_loader, layer_names=layer_names)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713d0c32-72e8-40f0-b1b9-c6ce6d5e6f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "k = torch.tensor([1.2, 1.3])\n",
    "dist = defaultdict(torch.Tensor)\n",
    "torch.cat([dist['testing'], torch.tensor([1.2, 1.3])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb799a91-c396-469a-8689-c281139a8170",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_assay = ClassificationNearestNeighbors(dataset='imagenette2_s320_remap1k', split='val')\n",
    "knn_assay.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d57f827-65b2-46a8-bc8e-02947fc92d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = models.alexnet(weights='IMAGENET1K_V1')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8695f5e-917f-443b-8ff9-a9a61a4ea963",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_names = ['avgpool', 'classifier.2', 'classifier.5', 'classifier.6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68490d0-0d8f-4bfe-9af4-17b030f9cac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde8a767-3800-4b76-84f0-871ef73b5e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = knn_assay.get_dataloader(transform)\n",
    "dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cffcb4e-0042-4a0e-8095-8accaf9d707b",
   "metadata": {},
   "outputs": [],
   "source": [
    "testFeatures, testLabels, indexes = get_features(model, dataloader, layer_names, \n",
    "                                                 out_device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea582c72-6499-43f6-a3db-edbf371ac91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_name in layer_names:\n",
    "    print(testFeatures[layer_name].shape, testFeatures[layer_name].dtype)\n",
    "    print(testLabels[layer_name].shape, testLabels[layer_name].dtype)\n",
    "    print(indexes[layer_name].shape, indexes[layer_name].dtype)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e823b47c-6ba1-4640-9446-c81f85c5dc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = gen_features(model, dataloader, layer_names, num_batches=3, out_device='cuda')\n",
    "num_total = 0\n",
    "for batch_num, (feat, lab, ind) in enumerate(generator):\n",
    "    print(batch_num, lab.shape, ind.shape)    \n",
    "    for layer_name, X in feat.items():\n",
    "        print(layer_name, X.shape)\n",
    "    num_total += X.shape[0]\n",
    "num_total, len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c59be01-3658-4875-827b-f42a709c0daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, transform = torch.hub.load(\"harvard-visionlab/open_ipcl\", \"alexnetgn_ipcl_ref01\",\n",
    "                                  trust_repo=True, force_reload=True)\n",
    "model.to(device)\n",
    "transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1454179-00e6-41b2-9ff9-cc3bd3574218",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d268217-3a9a-489b-bc13-90b4d07f1a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchvision.datasets import ImageNet\n",
    "from deep_analytics.datasets.folder import ImageNetIndex\n",
    "\n",
    "root = '/n/alvarez_lab_tier1/Users/alvarez/datasets/imagenet1k-256'\n",
    "train_dataset = ImageNetIndex(root, split='train', transform=transform)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71966869-8e63-4a1a-964c-d6bc731f047f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 256\n",
    "num_workers=len(os.sched_getaffinity(0))\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers, \n",
    "                          shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5618744-e9f7-4dc2-87b6-f5d4aa7a3800",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = train_loader\n",
    "test_loader = dataloader\n",
    "layer_names = ['avgpool', 'classifier.2', 'classifier.5', 'classifier.6']\n",
    "layer_names = ['ave_pool', 'fc6', 'fc7', 'fc8', 'l2norm']\n",
    "top1, top5 = run_kNN(model, train_loader, test_loader, layer_names, \n",
    "                     num_classes=1000, K=200, sigma=.07, num_chunks=10, \n",
    "                     out_device=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe5b34c-cbc1-4254-b12e-fea5ce68466b",
   "metadata": {},
   "outputs": [],
   "source": [
    "top1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f57ac2-ef92-4c8c-a593-bc675ae7b1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "top1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029c78ec-46a1-427d-8a5f-facd6333d3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "top1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1d8dcf-60ca-4a5c-ada1-d26940250631",
   "metadata": {},
   "outputs": [],
   "source": [
    "top5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056975ed-c000-46f7-b466-a81b34cdeb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "top5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adec6f33-e968-4d12-8e03-4790d31a31a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nethook\n",
    "\n",
    "def run_kNN_orig(model, train_loader, test_loader, layer_name, K=200, sigma=.07, num_chunks=200, out_device=None):\n",
    "    print(\"extracting training features...\")\n",
    "    trainFeatures, trainLabels, indexes = get_features_orig(model, train_loader, layer_name, out_device=out_device)\n",
    "    # trainFeatures = trainFeatures[layer_name]\n",
    "    \n",
    "    print(\"extracting test features...\")\n",
    "    testFeatures, testLabels, indexes = get_features_orig(model, test_loader, layer_name, out_device=out_device)\n",
    "    # testFeatures = testFeatures[layer_name]\n",
    "    \n",
    "    print(\"running kNN test...\")\n",
    "    \n",
    "    # split test features into chunks to avoid out-of-memory error:\n",
    "    chunkFeatures = torch.chunk(testFeatures, num_chunks, dim=0)\n",
    "    chunkLabels = torch.chunk(testLabels, num_chunks, dim=0)\n",
    "\n",
    "    C = trainLabels.max() + 1\n",
    "    top1, top5, total = 0., 0., 0.\n",
    "    for features, labels in progress_bar(zip(chunkFeatures, chunkLabels), total=num_chunks):\n",
    "        top1_, top5_, total_ = do_kNN(trainFeatures, trainLabels, features, labels, C, K, sigma)\n",
    "        top1 += top1_ / 100 * total_\n",
    "        top5 += top5_ / 100 * total_\n",
    "        total += total_\n",
    "    top1 = top1 / total * 100\n",
    "    top5 = top5 / total * 100\n",
    "    \n",
    "    print(f\"run_kNN accuracy: top1={top1}, top5={top5}\")\n",
    "    \n",
    "    return top1, top5\n",
    "\n",
    "def do_kNN(trainFeatures, trainLabels, testFeatures, testLabels, C, K, sigma, device=None, out_device=None):\n",
    "    '''\n",
    "        trainFeatures: [nTrainSamples, nFeatures]\n",
    "        trainLabels: [nTrainSamples]\n",
    "        \n",
    "        testFeatures: [nTestSamples, nFeatures]\n",
    "        testLabels: [nTestSamples]\n",
    "    '''\n",
    "    \n",
    "    if device is None:\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'            \n",
    "    \n",
    "    dist = torch.mm(testFeatures, trainFeatures.T).to(device)\n",
    "    \n",
    "    batchSize = len(testLabels)\n",
    "    \n",
    "    yd, yi = dist.topk(K, dim=1, largest=True, sorted=True)\n",
    "    \n",
    "    candidates = trainLabels.view(1,-1).expand(batchSize, -1)\n",
    "    \n",
    "    retrieval = torch.gather(candidates, 1, yi)\n",
    "    retrieval_one_hot = torch.zeros(K, C).to('cpu')\n",
    "    retrieval_one_hot.resize_(batchSize * K, C).zero_()\n",
    "    retrieval_one_hot.scatter_(1, retrieval.view(-1, 1).cpu(), 1)\n",
    "    yd_transform = yd.clone().div_(sigma).exp_()\n",
    "    probs = torch.sum(torch.mul(retrieval_one_hot.view(batchSize, -1 , C), yd_transform.view(batchSize, -1, 1).cpu()), 1)\n",
    "    _, predictions = probs.sort(1, True)\n",
    "    \n",
    "    # Find which predictions match the target\n",
    "    correct = predictions.eq(testLabels.view(-1,1).cpu())\n",
    "    correct.shape\n",
    "    \n",
    "    total = correct.size(0)\n",
    "    top1 = correct.narrow(1,0,1)\n",
    "    top5 = correct.narrow(1,0,5)\n",
    "    \n",
    "    return top1, top5, total\n",
    "\n",
    "def get_features_orig(model, dataloader, layer_name, device=None, out_device=None):    \n",
    "    if not isinstance(model, nethook.InstrumentedModel):\n",
    "        model = nethook.InstrumentedModel(model)\n",
    "    model.retain_layers([layer_name])\n",
    "    features,labels,indexes = [],[],[]\n",
    "    if device is None:\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    if out_device is None:\n",
    "        out_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        \n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for imgs,targs,idxs in progress_bar(dataloader):\n",
    "            out = model(imgs.to(device))\n",
    "            X = model.retained_layer(layer_name)\n",
    "            X = F.normalize(X, dim=1)\n",
    "            X = X.view(X.shape[0], -1)\n",
    "            features.append(X.to(out_device))\n",
    "            labels.append(targs.to(out_device))\n",
    "            indexes.append(idxs.to(out_device))\n",
    "    \n",
    "    features = torch.cat(features)\n",
    "    labels = torch.cat(labels)\n",
    "    indexes = torch.cat(indexes)\n",
    "    \n",
    "    return features, labels, indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0fe74a-e950-4209-a897-5e7b62e27821",
   "metadata": {},
   "outputs": [],
   "source": [
    "top1_, top5_ = run_kNN_orig(model, train_loader, test_loader, 'fc8', K=200, sigma=.07, \n",
    "                            num_chunks=200, out_device=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2743873-bc36-4863-aca8-5a2b38749c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_name = 'fc8'\n",
    "out_device = None\n",
    "\n",
    "print(\"extracting training features...\")\n",
    "trainFeatures, trainLabels, indexes = get_features_orig(model, train_loader, layer_name, out_device=out_device)\n",
    "# trainFeatures = trainFeatures[layer_name]\n",
    "\n",
    "print(\"extracting test features...\")\n",
    "testFeatures, testLabels, indexes = get_features_orig(model, test_loader, layer_name, out_device=out_device)\n",
    "# testFeatures = testFeatures[layer_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4122ef65-4f90-44d9-ba08-f17af4ebf6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split test features into chunks to avoid out-of-memory error:\n",
    "num_chunks = 200\n",
    "K = 200\n",
    "sigma = .07\n",
    "chunkFeatures = torch.chunk(testFeatures, num_chunks, dim=0)\n",
    "chunkLabels = torch.chunk(testLabels, num_chunks, dim=0)\n",
    "\n",
    "C = trainLabels.max() + 1\n",
    "top1, top5 = [], []\n",
    "for features, labels in progress_bar(zip(chunkFeatures, chunkLabels), total=num_chunks):\n",
    "    top1_, top5_, total_ = do_kNN(trainFeatures, trainLabels, features, labels, C, K, sigma)\n",
    "    top1.append(top1_)\n",
    "    top5.append(top5_)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dc8858-0e3a-4b52-b1c2-0dff797cdf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cat(top1).float().mean().item() * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6b9161-6299-4c63-8867-ffac8fcb6837",
   "metadata": {},
   "source": [
    "# ClassificationNearestPrototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea52f785-b43c-450a-9608-3f5d1652fc86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis",
   "language": "python",
   "name": "analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
