{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84a6c7e-02fc-406a-906f-44148b6e27f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3daabcd-611d-4d02-b7ff-5c5d549702ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_analytics.assays import AdversarialAttacks, AttackTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168b1176-db19-4a36-9484-a7543e6749eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "AttackTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f5c14b-1ddc-4e45-afd4-e10ad270eb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "AdversarialAttacks.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f68d12-adb2-41cd-be13-4915dfbbd304",
   "metadata": {},
   "outputs": [],
   "source": [
    "assay_adv_attack = AdversarialAttacks('imagenette2_s320_remap1k', split='val')\n",
    "assay_adv_attack.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3188104c-d7af-459e-8008-830804580da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "img,label,index = assay_adv_attack.dataset[0]\n",
    "print(label,index,img.size)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6be452-bbe9-48b4-a5ca-87bc89c04422",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models, transforms\n",
    "from functools import partial\n",
    "from model_rearing_workshop.models import load_model_from_weights\n",
    "from model_rearing_workshop.models.weights import get_standard_transforms, Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f92d19-b1c0-47c8-8d26-be006e483285",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = Weights(\n",
    "    url='https://visionlab-members.s3.wasabisys.com/alvarez/Projects/model_rearing_workshop/models/in1k/alexnet2023_layer_diffnoise_scaled_sqrt1/supervised/20231122_102040/final_weights-42b687fb09.pth',\n",
    "    transforms=get_standard_transforms(), # Add your transforms here\n",
    "    meta={\n",
    "        \"repo\": \"https://github.com/harvard-visionlab/alexnets\",\n",
    "        \"urls\": dict(\n",
    "            params='https://visionlab-members.s3.wasabisys.com/alvarez/Projects/model_rearing_workshop/models/in1k/alexnet2023_layer_diffnoise_scaled_sqrt1/supervised/20231122_102040/params-42b687fb09.json',\n",
    "            train='https://visionlab-members.s3.wasabisys.com/alvarez/Projects/model_rearing_workshop/models/in1k/alexnet2023_layer_diffnoise_scaled_sqrt1/supervised/20231122_102040/log_train-42b687fb09.txt',\n",
    "            val='https://visionlab-members.s3.wasabisys.com/alvarez/Projects/model_rearing_workshop/models/in1k/alexnet2023_layer_diffnoise_scaled_sqrt1/supervised/20231122_102040/log_val-42b687fb09.txt',\n",
    "        ),\n",
    "        \"_metrics\": {},\n",
    "        \"_docs\": \"\"\"\n",
    "            ....\n",
    "        \"\"\",\n",
    "    },\n",
    ")\n",
    "transform = alexnet2023_layer_diffnoise_scaled_sqrt1.transforms['val_transform']\n",
    "transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3deca613-b8d0-4c68-b89f-9ee26b9c37ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from functools import partial\n",
    "import contextlib\n",
    "import io\n",
    "import sys\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def suppress_stdout():\n",
    "    new_stdout = io.StringIO()\n",
    "    old_stdout = sys.stdout\n",
    "    sys.stdout = new_stdout\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        sys.stdout = old_stdout\n",
    "        \n",
    "class ModelWrapper(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__() \n",
    "        self.model = model\n",
    "    def forward(self, x):\n",
    "        embeddings, layer_outputs, layer_logits = self.model(x)\n",
    "        return embeddings\n",
    "    \n",
    "def load_model_eval(weights):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    with suppress_stdout():\n",
    "        model = load_model_from_weights(weights)\n",
    "    \n",
    "    wrapped_model = ModelWrapper(model)\n",
    "    wrapped_model.model_name = 'alexnet2023_layer_diffnoise_scaled_sqrt1'\n",
    "    wrapped_model.to(device)\n",
    "    wrapped_model.eval()\n",
    "    \n",
    "    return wrapped_model\n",
    "\n",
    "def load_model_train(weights):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    with suppress_stdout():\n",
    "        model = load_model_from_weights(weights)\n",
    "    \n",
    "    wrapped_model = ModelWrapper(model)\n",
    "    wrapped_model.model_name = 'alexnet2023_layer_diffnoise_scaled_sqrt1'\n",
    "    wrapped_model.to(device)\n",
    "    wrapped_model.train()\n",
    "    \n",
    "    return wrapped_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1792c22d-a9c1-4035-9147-3024da705432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model_eval()\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7725594-1859-4b86-a4bc-a6bf03f11d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_eval = assay_adv_attack.run(load_model_eval, transform, attack=AttackTypes.FGSM)\n",
    "results_eval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c132f2-7b6a-4394-8f86-cca5e8e6a28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assay_adv_attack.plot_results(results_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328dfe44-14cf-4f27-a527-77076af9e271",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_train = assay_adv_attack.run(load_model_train, transform, attack=AttackTypes.FGSM)\n",
    "results_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53f34b4-543c-4f3c-b5a0-d27cbd73f471",
   "metadata": {},
   "outputs": [],
   "source": [
    "assay_adv_attack.plot_results(results_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91347b18-c638-4d6b-afd5-ad456d457022",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset1 = results_eval[results_eval.image_set=='adversarial']\n",
    "subset1['mode'] = 'eval'\n",
    "subset2 = results_train[results_train.image_set=='adversarial']\n",
    "subset2['mode'] = 'train'\n",
    "\n",
    "df = pd.concat([subset1, subset2])\n",
    "assay_adv_attack.plot_results(df, hue=\"mode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82da957-9a4b-4c61-9ac0-6db23f10184e",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = Weights(\n",
    "    url='https://visionlab-members.s3.wasabisys.com/alvarez/Projects/model_rearing_workshop/models/in1k/alexnet2023_inp_diffnoise_scaled_sqrt0/supervised/20231122_102051/final_weights-1d52da36f3.pth',\n",
    "    transforms=get_standard_transforms(), # Add your transforms here\n",
    "    meta={\n",
    "        \"repo\": \"https://github.com/harvard-visionlab/alexnets\",\n",
    "        \"urls\": dict(\n",
    "            params='https://visionlab-members.s3.wasabisys.com/alvarez/Projects/model_rearing_workshop/models/in1k/alexnet2023_inp_diffnoise_scaled_sqrt0/supervised/20231122_102051/params-1d52da36f3.json',\n",
    "            train='https://visionlab-members.s3.wasabisys.com/alvarez/Projects/model_rearing_workshop/models/in1k/alexnet2023_inp_diffnoise_scaled_sqrt0/supervised/20231122_102051/log_train-1d52da36f3.txt',\n",
    "            val='https://visionlab-members.s3.wasabisys.com/alvarez/Projects/model_rearing_workshop/models/in1k/alexnet2023_inp_diffnoise_scaled_sqrt0/supervised/20231122_102051/log_val-1d52da36f3.txt',\n",
    "        ),\n",
    "        \"_metrics\": {},\n",
    "        \"_docs\": \"\"\"\n",
    "            ....\n",
    "        \"\"\",\n",
    "    },\n",
    ")\n",
    "load_model = partial(load_model_eval, weights)\n",
    "transform = weights.transforms['val_transform']\n",
    "transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2378bdfa-ac52-4bc8-9881-c9dc660c20f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_2 = assay_adv_attack.run(load_model, transform, attack=AttackTypes.FGSM)\n",
    "results_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957b8ce5-984c-40e4-9ab1-ef682d203f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "assay_adv_attack.plot_results(results_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304035d0-c329-47a6-b088-c8b29c1f334b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights = Weights(\n",
    "#     url='https://visionlab-members.s3.wasabisys.com/alvarez/Projects/model_rearing_workshop/models/in1k/alexnet2023_baseline/barlow/20231116_044210/final_weights-0b70b9da61.pth',\n",
    "#     transforms=get_standard_transforms(), # Add your transforms here\n",
    "#     meta={\n",
    "#         \"repo\": \"https://github.com/harvard-visionlab/alexnets\",\n",
    "#         \"urls\": dict(\n",
    "#             params='https://visionlab-members.s3.wasabisys.com/alvarez/Projects/model_rearing_workshop/models/in1k/alexnet2023_baseline/barlow/20231116_044210/params-0b70b9da61.json',\n",
    "#             train='https://visionlab-members.s3.wasabisys.com/alvarez/Projects/model_rearing_workshop/models/in1k/alexnet2023_baseline/barlow/20231116_044210/log_train-0b70b9da61.txt',\n",
    "#             val='https://visionlab-members.s3.wasabisys.com/alvarez/Projects/model_rearing_workshop/models/in1k/alexnet2023_baseline/barlow/20231116_044210/log_val-0b70b9da61.txt',\n",
    "#         ),\n",
    "#         \"_metrics\": {},\n",
    "#         \"_docs\": \"\"\"\n",
    "#             ....\n",
    "#         \"\"\",\n",
    "#     },\n",
    "# )\n",
    "\n",
    "weights = Weights(\n",
    "    url='https://visionlab-members.s3.wasabisys.com/alvarez/Projects/model_rearing_workshop/models/in1k/alexnet2023_baseline/supervised/20231115_062107/final_weights-b0b1f89b7a.pth',\n",
    "    transforms=get_standard_transforms(), # Add your transforms here\n",
    "    meta={\n",
    "        \"repo\": \"https://github.com/harvard-visionlab/alexnets\",\n",
    "        \"urls\": dict(\n",
    "            params='https://visionlab-members.s3.wasabisys.com/alvarez/Projects/model_rearing_workshop/models/in1k/alexnet2023_baseline/supervised/20231115_062107/params-b0b1f89b7a.json',\n",
    "            train='https://visionlab-members.s3.wasabisys.com/alvarez/Projects/model_rearing_workshop/models/in1k/alexnet2023_baseline/supervised/20231115_062107/log_train-b0b1f89b7a.txt',\n",
    "            val='https://visionlab-members.s3.wasabisys.com/alvarez/Projects/model_rearing_workshop/models/in1k/alexnet2023_baseline/supervised/20231115_062107/log_val-b0b1f89b7a.txt',\n",
    "        ),\n",
    "        \"_metrics\": {},\n",
    "        \"_docs\": \"\"\"\n",
    "            ....\n",
    "        \"\"\",\n",
    "    },\n",
    ")\n",
    "\n",
    "load_model = partial(load_model_eval, weights)\n",
    "transform = weights.transforms['val_transform']\n",
    "transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6c53d9-3f9b-4df7-a9b1-9db28073e3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_baseline = assay_adv_attack.run(load_model, transform, attack=AttackTypes.FGSM)\n",
    "results_baseline.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d503ee1c-ab32-4878-add0-b528699a664c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assay_adv_attack.plot_results(results_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23ced55-ed8d-4782-b648-838a86bdcb4a",
   "metadata": {},
   "source": [
    "# Quantify Robustness\n",
    "\n",
    "1. convert pandas dataframe to numpy array\n",
    "2. compute mean and upper/lower CI for each image_set + epsilon combo\n",
    "3. Compute robustness scores\n",
    "- [ ] normalized AUC sum(acc_by_eps / acc_eps_0)\n",
    "- [ ] normalized acc mean(acc_by_eps/acc_eps_0)\n",
    "- [ ] compute equal-weighted robust accuracy: \n",
    "    weights = [1.0] * len(epsilons)  # Equal weights\n",
    "    robust_accuracy = clean_accuracy - np.average(adversarial_accuracies, weights=weights)\n",
    "- [ ] compute weighted robust accuracy\n",
    "    weights = 1/epsilons[1:] # Inverse proportional weights\n",
    "    robust_accuracy = clean_accuracy - np.average(adversarial_accuracies, weights=weights)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b412e3-cce6-482f-8299-a2eb99ae5f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_analytics.assays.adversarial_attacks.adversarial_attacks import dataframe_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a28a47-a670-4cc4-aa28-4ff87491fbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = dataframe_to_array(results_baseline[results_baseline.image_set=='adversarial'], 'correct1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24f174f-726f-4373-bf69-9b6d45cbaa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(arr.keys())\n",
    "print(arr['dims'])\n",
    "D = arr['D']\n",
    "epsilons = np.array(arr['epsilons'])\n",
    "D.shape, epsilons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb67029-a5b3-4f10-9afc-bb809ebaa9e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59553a13-5af6-4a98-beb1-c7aac2ecacb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from functools import partial\n",
    "from fastprogress import progress_bar \n",
    "\n",
    "class AccumMetric:\n",
    "    def __init__(self, scoring_func, ci_level=0.95):\n",
    "        self.scores = []\n",
    "        self.scoring_func = scoring_func\n",
    "        self.ci_level = ci_level    \n",
    "\n",
    "    def reset(self):\n",
    "        self.scores = []\n",
    "\n",
    "    def stats(self, ci_level=None, axis=None):\n",
    "        if not self.scores:\n",
    "            return None\n",
    "        ci_level = self.ci_level if ci_level is None else ci_level\n",
    "        axis = 0 if axis is None else axis\n",
    "        \n",
    "        # Calculate the mean\n",
    "        mean_score = np.mean(self.scores, axis=axis)\n",
    "\n",
    "        # Calculate the lower and upper percentiles for the confidence interval\n",
    "        lower_percentile = 100 * (1 - self.ci_level) / 2\n",
    "        upper_percentile = 100 * (1 + self.ci_level) / 2\n",
    "\n",
    "        lower_ci = np.percentile(self.scores, lower_percentile, axis=axis)\n",
    "        upper_ci = np.percentile(self.scores, upper_percentile, axis=axis)\n",
    "\n",
    "        return {\n",
    "            \"mean\": mean_score,\n",
    "            f\"{int(self.ci_level * 100)}% CI\": (lower_ci, upper_ci),\n",
    "        }\n",
    "    \n",
    "    def __call__(self, data):\n",
    "        # Calculate the score using the provided scoring function\n",
    "        score = self.scoring_func(data)\n",
    "        self.scores.append(score)\n",
    "        \n",
    "def estimate_thresh_crossing(xs, ys, threshold):\n",
    "    crossings = []\n",
    "\n",
    "    for i in range(len(xs) - 1):\n",
    "        x1, x2 = xs[i], xs[i + 1]\n",
    "        y1, y2 = ys[i], ys[i + 1]\n",
    "\n",
    "        if (y1 < threshold and y2 >= threshold) or (y1 >= threshold and y2 < threshold):\n",
    "            # Linear interpolation to estimate the crossing point\n",
    "            slope = (y2 - y1) / (x2 - x1)\n",
    "            intercept = y1 - slope * x1\n",
    "            crossing_x = (threshold - intercept) / slope\n",
    "            crossings.append(crossing_x)\n",
    "\n",
    "    if crossings:\n",
    "        # Calculate the average crossing point if multiple crossings occurred\n",
    "        estimated_epsilon = np.mean(crossings)\n",
    "    else:\n",
    "        estimated_epsilon = None\n",
    "\n",
    "    return estimated_epsilon, crossings\n",
    "\n",
    "def compute_normalized_acc_by_eps(data, epsilons, dim=-1):\n",
    "    acc_by_eps = data.mean(axis=dim)\n",
    "    return acc_by_eps\n",
    "\n",
    "def compute_normalized_auc(data, epsilons, dim=-1):\n",
    "    assert epsilons[0]==0, f\"oops, expected first epsilon to be zero, got {epsilons[0]}\"\n",
    "    acc_by_eps = data.mean(axis=dim)\n",
    "    clean_accuracy = acc_by_eps[0]\n",
    "    normed_acc = acc_by_eps / clean_accuracy\n",
    "    normalized_auc = np.sum(normed_acc)\n",
    "    return normalized_auc\n",
    "\n",
    "def compute_normalized_acc(data, epsilons, dim=-1):\n",
    "    assert epsilons[0]==0, f\"oops, expected first epsilon to be zero, got {epsilons[0]}\"\n",
    "    acc_by_eps = data.mean(axis=dim)\n",
    "    clean_accuracy = acc_by_eps[0]\n",
    "    normed_acc = acc_by_eps / clean_accuracy\n",
    "    normalized_acc = np.mean(normed_acc)\n",
    "    return normalized_acc\n",
    "\n",
    "def compute_weighted_adv_acc(data, epsilons, dim=-1, normalize=True):\n",
    "    assert epsilons[0]==0, f\"oops, expected first epsilon to be zero, got {epsilons[0]}\"\n",
    "    acc_by_eps = data.mean(axis=-1)\n",
    "    clean_accuracy = acc_by_eps[0]\n",
    "    adv_accuracies = acc_by_eps[1:]\n",
    "    if normalize:\n",
    "        adv_accuracies = adv_accuracies / clean_accuracy\n",
    "    weighted_adv_acc = np.average(adv_accuracies, weights=1/epsilons[1:])\n",
    "    return weighted_adv_acc\n",
    "\n",
    "def compute_thresh_half_minmax(data, epsilons, dim=-1, normalize=True):\n",
    "    assert epsilons[0]==0, f\"oops, expected first epsilon to be zero, got {epsilons[0]}\"\n",
    "    acc_by_eps = data.mean(axis=dim)\n",
    "    clean_accuracy = acc_by_eps[0]\n",
    "    normed_acc = acc_by_eps / clean_accuracy\n",
    "    half_max = normed_acc.min() + (normed_acc.max() - normed_acc.min())/2\n",
    "    thresh_half_minmax, _ = estimate_thresh_crossing(epsilons, normed_acc, half_max)\n",
    "    \n",
    "    return thresh_half_minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4c5f86-5b53-4491-937e-a373da6c2c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_analytics.utils.bootstrap import bootstrap_multi_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ffccb2-301f-4d3b-b7f5-a7472d596cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "samples = bootstrap_multi_dim(D[0,0], dims=(1), n_bootstrap=1000, seed=1234)\n",
    "\n",
    "metrics = [\n",
    "    AccumMetric(partial(compute_normalized_acc_by_eps, epsilons=epsilons)),\n",
    "    AccumMetric(partial(compute_normalized_auc, epsilons=epsilons)),\n",
    "    AccumMetric(partial(compute_normalized_acc, epsilons=epsilons)),\n",
    "    AccumMetric(partial(compute_weighted_adv_acc, epsilons=epsilons, normalize=True)),\n",
    "    AccumMetric(partial(compute_thresh_half_minmax, epsilons=epsilons, normalize=True))\n",
    "]\n",
    "\n",
    "for sample in progress_bar(samples):\n",
    "    for metric in metrics: \n",
    "        metric(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7905b003-463d-42a5-b869-f1ad81501969",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = dict([\n",
    "            ('acc_by_eps', AccumMetric(partial(compute_normalized_acc_by_eps, epsilons=epsilons))),\n",
    "            ('norm_auc', AccumMetric(partial(compute_normalized_auc, epsilons=epsilons))),\n",
    "            ('norm_acc', AccumMetric(partial(compute_normalized_acc, epsilons=epsilons))),\n",
    "            ('weighted_norm_acc', AccumMetric(partial(compute_weighted_adv_acc, epsilons=epsilons, normalize=True))),\n",
    "            ('thresh_half_minmax', AccumMetric(partial(compute_thresh_half_minmax, epsilons=epsilons, normalize=True)))\n",
    "        ])\n",
    "metrics.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0faba1-efed-4289-a0e7-94a7f31a04a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(metrics[0].scores).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb7aa95-3782-408c-897c-df7310181ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics[0].stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb5a7e9-43ad-435a-a907-bbecd04eec39",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics[1].stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39da1e1d-c44a-4657-be3a-3f37211f8730",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics[2].stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b51a17f-ba7a-48ac-b669-4b54c216074c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics[3].stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60850d6-b5ad-45ab-8bb2-d47dbf837830",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics[4].stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ec83f3-1baa-4ed0-9b62-e41ee34b44f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert epsilons[0]==0\n",
    "acc_by_eps = D[0,0].mean(axis=1)\n",
    "clean_accuracy = acc_by_eps[0]\n",
    "adv_accuracies = acc_by_eps[1:]\n",
    "normed_acc = acc_by_eps / clean_accuracy\n",
    "normalized_auc = np.sum(normed_acc)\n",
    "normalized_acc = np.mean(normed_acc)\n",
    "weighted_adv_acc = np.average(adv_accuracies, weights=1/epsilons[1:])\n",
    "half_max = normed_acc.min() + (normed_acc.max() - normed_acc.min())/2\n",
    "thresh_half_minmax, _ = estimate_thresh_crossing(epsilons, normed_acc, half_max)\n",
    "\n",
    "normalized_auc, normalized_acc, weighted_adv_acc, thresh_half_minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c422359-917e-439c-9be2-76cacda603ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7eda8d-f3cc-450b-a73f-4670c621ad69",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_by_eps, epsilons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d03dbd0-b907-4e27-8bb2-4893be77475c",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimate_epsilon_crossing(epsilons, acc_by_eps, 1/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d5e3ff-ecb4-4949-8162-34b6d2f8cb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import numpy as np\n",
    "# from numpy.random import RandomState\n",
    "# from fastprogress import progress_bar \n",
    "\n",
    "# def dataframe_to_array(df, data_column):\n",
    "#     '''\n",
    "#         convert dataframe into a numModels x numImageSets x numEpsilons x numItems array\n",
    "#     '''\n",
    "#     model_names = list(df.model_name.unique())\n",
    "#     image_sets = list(df.image_set.unique())\n",
    "#     epsilons = sorted(list(df.epsilon.unique()))\n",
    "#     item_names = list(df.filenames.unique())\n",
    "    \n",
    "#     D = np.empty((len(model_names),len(image_sets),len(epsilons),len(item_names)))\n",
    "#     D[:] = np.nan\n",
    "#     for rownum,row in progress_bar(df.iterrows(), total=len(df)):\n",
    "#         model_num = model_names.index(row.model_name)\n",
    "#         imageset_num = image_sets.index(row.image_set)\n",
    "#         epsilon_num = epsilons.index(row.epsilon)\n",
    "#         item_num = item_names.index(row.filenames)\n",
    "#         curr_val = D[model_num, imageset_num, epsilon_num, item_num]\n",
    "#         assert np.isnan(curr_val), f\"Oops, expected current value to be nan, got {curr_val}\"    \n",
    "#         D[model_num, imageset_num, epsilon_num, item_num] = row[data_column]\n",
    "#     assert np.isnan(D).any() == False, \"Oops, expected all values to be filled, found nans\"    \n",
    "    \n",
    "#     return dict(\n",
    "#         D=D,\n",
    "#         dims=['model_name', 'image_set', 'epsilon', 'filename'],\n",
    "#         model_names=model_names,\n",
    "#         image_sets=image_sets,\n",
    "#         epsilons=epsilons,\n",
    "#         item_names=item_names\n",
    "#     )\n",
    "\n",
    "# def bootstrap_single_dim(D, dim, n_bootstrap=1000, seed=123):\n",
    "#     num_items = D.shape[dim]\n",
    "    \n",
    "#     # Initialize the random number generator\n",
    "#     rng = RandomState(seed)\n",
    "    \n",
    "#     # Generate bootstrap samples\n",
    "#     samples = rng.choice(num_items, size=(n_bootstrap, num_items), replace=True)\n",
    "\n",
    "#     # Select the samples along the specified dimension\n",
    "#     bootstrap_samples = np.take(D, samples, axis=dim)\n",
    "    \n",
    "#     # Move the bootstrap dimension to the first position\n",
    "#     bootstrap_samples = np.moveaxis(bootstrap_samples, dim, 0)\n",
    "    \n",
    "#     return bootstrap_samples\n",
    "\n",
    "# def bootstrap_multi_dim_slow_loop_test(D, dims, n_bootstrap=10000, seed=123):\n",
    "#     rng = RandomState(seed)\n",
    "\n",
    "#     # Initialize the bootstrap sample array\n",
    "#     new_shape = list(D.shape) + [n_bootstrap]\n",
    "#     bootstrap_samples = np.empty(new_shape, dtype=D.dtype)\n",
    "\n",
    "#     for i in range(n_bootstrap):\n",
    "#         # Initialize indices for this bootstrap sample\n",
    "#         indices = [slice(None)] * D.ndim\n",
    "\n",
    "#         # Replace indices for the bootstrapped dimensions\n",
    "#         for dim in dims:\n",
    "#             num_items = D.shape[dim]\n",
    "#             indices[dim] = rng.choice(num_items, size=num_items, replace=True)\n",
    "\n",
    "#         # Using advanced indexing to select elements for the bootstrap sample\n",
    "#         bootstrap_samples[..., i] = D[np.ix_(*indices)]\n",
    "\n",
    "#     return bootstrap_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd084e92-bacc-40c7-b97a-91d6920c9543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(df.cond_name.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2ae9d4-c7dc-4827-a22f-d096e073da57",
   "metadata": {},
   "source": [
    "# figure out multi-dimensionsal bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c598cc09-fb0a-48b9-8faf-c12700a6279d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import numpy as np\n",
    "# from numpy.random import RandomState\n",
    "\n",
    "# def generate_test_data(num_subjects=3, num_conds=2, num_items=5):\n",
    "#     D = np.zeros((num_subjects, num_conds, num_items))\n",
    "\n",
    "#     # Populate the array with unique values for each subject and each item\n",
    "#     for subject in range(num_subjects):\n",
    "#         for cond in range(num_conds):\n",
    "#             # Offset each condition by 100\n",
    "#             D[subject, cond, :] = np.arange(subject * 100, subject * 100 + num_items) + (cond * 100)\n",
    "    \n",
    "#     return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c530787d-ac53-4458-9bfe-fd19f1351f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from functools import reduce\n",
    "# from fastprogress import progress_bar\n",
    "\n",
    "# def bootstrap_multi_dim(D, dims, n_bootstrap=10000, seed=None, vectorized=False):\n",
    "#     \"\"\"\n",
    "#     Perform bootstrap resampling across specified dimensions of a multi-dimensional array.\n",
    "\n",
    "#     Args:\n",
    "#     D (numpy.ndarray): The input array from which to sample.\n",
    "#     dims (int or tuple of ints): The dimensions over which to perform bootstrapping.\n",
    "#     n_bootstrap (int): The number of bootstrap samples to generate.\n",
    "#     seed (int): Random seed for reproducibility.\n",
    "#     vectorized (bool): Whether to use vectorized indexing (flatten data, use flat_indices)\n",
    "    \n",
    "#     Returns:\n",
    "#     numpy.ndarray: An array of bootstrapped samples. The shape of the array is \n",
    "#                    (n_bootstrap, *D.shape), where the first dimension corresponds\n",
    "#                    to the bootstrap samples, and the remaining dimensions correspond\n",
    "#                    to the dimensions of the original array.\n",
    "\n",
    "#     The function generates random indices for the specified dimensions (dims) and \n",
    "#     uses the original indices for the other dimensions. These indices are expanded \n",
    "#     and scaled by the array's strides to calculate the flat indices, which are then \n",
    "#     used to index into a flattened version of the original array. The resulting \n",
    "#     samples are reshaped to form an array that retains the structure of the original \n",
    "#     array while incorporating the bootstrap dimension.\n",
    "#     \"\"\"    \n",
    "#     if isinstance(dims, int): dims = (dims,)\n",
    "\n",
    "#     rng = RandomState(seed)\n",
    "\n",
    "#     # Generate random indices for each specified dimension, repeat original indices for other dimensions\n",
    "#     indices = [rng.choice(D.shape[dim], size=(n_bootstrap, D.shape[dim]), replace=True) \n",
    "#                if dim in dims else np.arange(D.shape[dim])[None,:].repeat(n_bootstrap, 0)\n",
    "#                for dim in range(D.ndim)]\n",
    "\n",
    "#     if vectorized:\n",
    "#         bootstrap_samples = vectorized_indexing(D, indices)\n",
    "#     else:\n",
    "#         bootstrap_samples = loop_indexing(D, indices)\n",
    "    \n",
    "#     return bootstrap_samples\n",
    "\n",
    "# def loop_indexing(D, indices):\n",
    "    \n",
    "#     n_bootstrap = indices[0].shape[0]\n",
    "    \n",
    "#     # Initialize the bootstrap sample array\n",
    "#     new_shape = [n_bootstrap] + list(D.shape)\n",
    "#     bootstrap_samples = np.empty(new_shape, dtype=D.dtype)\n",
    "\n",
    "#     # Iterate over the indices for each bootstrap sample\n",
    "#     for i, curr_indices in enumerate(progress_bar(zip(*indices), total=n_bootstrap)):\n",
    "#         # Use advanced indexing to select the sample\n",
    "#         bootstrap_samples[i] = D[np.ix_(*curr_indices)]\n",
    "    \n",
    "#     # Now, bootstrap_samples contains the bootstrapped samples    \n",
    "#     return bootstrap_samples\n",
    "\n",
    "# def vectorized_indexing(D, indices):\n",
    "#     n_bootstrap = indices[0].shape[0]\n",
    "    \n",
    "#     # Calculate the strides for each dimension in D\n",
    "#     strides = np.array(D.strides) // D.itemsize\n",
    "\n",
    "#     # Flatten the array D\n",
    "#     D_flat = D.reshape(-1)\n",
    "    \n",
    "#     # lambda function to expand dimensions on indices so they broadcast correctly when summed\n",
    "#     # e.g., if D is 5x2x100, n_bootstrap=1000, then reshape indices dim=0 to be 1000x5x1x1, etc.\n",
    "#     adjusted_axes = lambda dim: [i+1 for i in range(D.ndim) if i != dim]\n",
    "    \n",
    "#     # Expand Dims and Multiply each set of indices with the corresponding stride before summing\n",
    "#     scaled_indices = [np.ascontiguousarray(np.expand_dims(idx, axis=adjusted_axes(dim)) * stride).astype(np.int32)\n",
    "#                       for dim, (idx, stride) in enumerate(zip(indices, strides))]\n",
    "\n",
    "#     # Perform the direct summation using reduce (np.add performs the correct broadcasting)\n",
    "#     flat_indices = reduce(np.add, scaled_indices)\n",
    "    \n",
    "#     # Use the flat indices to access the data values\n",
    "#     bootstrap_samples_flat = D_flat[flat_indices]\n",
    "    \n",
    "#     # reshape \n",
    "#     bootstrap_samples = bootstrap_samples_flat.reshape(n_bootstrap, *D.shape)\n",
    "    \n",
    "#     return bootstrap_samples\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf4f85d-d4ed-498a-be56-876ea2d4206f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D = generate_test_data()\n",
    "# print(\"Original Data:\")\n",
    "# print(D)\n",
    "# print(D.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea2c7af-b80d-471a-95a0-700561af0eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D = torch.rand((10,2,1260)).numpy()\n",
    "# D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6c7778-4b5a-4031-86cb-78541dd2eec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "\n",
    "# start = time.time()\n",
    "# bs_samples1 = bootstrap_multi_dim(D, dims=(0,2), seed=123, vectorized=False)\n",
    "# dur = time.time() - start\n",
    "# bs_samples1.shape, dur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557bb9b5-dc92-49fd-b947-daefd2830593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "\n",
    "# start = time.time()\n",
    "# bs_samples2 = bootstrap_multi_dim(D, dims=(0,2), seed=123, vectorized=True)\n",
    "# dur = time.time() - start\n",
    "# bs_samples2.shape, dur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5956f4df-8279-4ec8-865a-286fe30f1872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.equal(bs_samples1, bs_samples2).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b6b17a-29a7-4239-a86d-24074b2e3130",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workshop",
   "language": "python",
   "name": "workshop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
